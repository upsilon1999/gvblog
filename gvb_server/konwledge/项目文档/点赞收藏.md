## 文章浏览量

由于我们将文章浏览次数存入了es，但是不应该每浏览一次就去es里存一次，那样对es的操作太频繁了，所以可以先存入缓存，然后找合适的时机同步

1.用户点赞一篇文章，就将这个文章id存入缓存

```go
{
"id1": 2,
"id2": 10,
...
}
```

2.redis服务书写

```go
package redis_ser

import (
	"gvb_server/core"
	"gvb_server/global"
	"strconv"

	"github.com/sirupsen/logrus"
)

const diggPrefix = "digg"

// Digg 点赞某一篇文章
func Digg(id string) error {
	num, err := global.Redis.HGet(core.RedisCtx,diggPrefix, id).Int()
	if err!=nil{
		logrus.Errorf("获取id错误,错误为%v",err)
		return err
	}
	num++
	err = global.Redis.HSet(core.RedisCtx,diggPrefix, id, num).Err()
	if err!=nil{
		logrus.Errorf("获取id下点赞数出错,错误为%v",err)
		return err
	}
	return nil
}

// GetDigg 获取某一篇文章下的点赞数
func GetDigg(id string) int {
	num, err := global.Redis.HGet(core.RedisCtx,diggPrefix, id).Int()
	if err!=nil{
		logrus.Errorf("获取点赞数出错,错误为%v",err)
		return 0
	}
	return num
}

// GetDiggInfo 取出点赞数据
func GetDiggInfo() map[string]int {
	var DiggInfo = map[string]int{}
	maps := global.Redis.HGetAll(core.RedisCtx,diggPrefix).Val()
	for id, val := range maps {
		num, _ := strconv.Atoi(val)
		DiggInfo[id] = num
	}
	return DiggInfo
}

//清除点赞数据
func DiggClear() {
	global.Redis.Del(core.RedisCtx,diggPrefix)
}
```

### 将数据同步到es的逻辑

这个目前考虑定时任务，现在先书写逻辑

1.从redis中取出数据

```go
package redis_ser

import (
	"gvb_server/core"
	"gvb_server/global"
	"strconv"

	"github.com/sirupsen/logrus"
)

const diggPrefix = "digg"
// GetDiggInfo 取出点赞数据
func GetDiggInfo() map[string]int {
	var DiggInfo = map[string]int{}
	maps := global.Redis.HGetAll(core.RedisCtx,diggPrefix).Val()
	for id, val := range maps {
		num, _ := strconv.Atoi(val)
		DiggInfo[id] = num
	}
	return DiggInfo
}
```

2.同步完后应该还有清除操作

```go
package redis_ser

import (
	"gvb_server/core"
	"gvb_server/global"
	"strconv"

	"github.com/sirupsen/logrus"
)

const diggPrefix = "digg"

//清除相关缓存
func DiggClear() {
  global.Redis.Del(diggPrefix)
}
```

3.将数据同步的es(此处只是逻辑)

```go
func main() {
  // 读取配置文件
  core.InitConf()
  // 初始化日志
  global.Log = core.InitLogger()

  global.Redis = core.ConnectRedis()
  global.ESClient = core.EsConnect()

  result, err := global.ESClient.
    Search(models.ArticleModel{}.Index()).
    Query(elastic.NewMatchAllQuery()).
    Size(10000).
    Do(context.Background())
  if err != nil {
    logrus.Error(err)
    return
  }

  //从redis获取点赞数据
  diggInfo := redis_ser.GetDiggInfo()
    
  for _, hit := range result.Hits.Hits {
    var article models.ArticleModel
    //对于我们来说这里还有一个问题，
    //es中存的是digg_count，而我们json映射是diggCount
    //所以读取时需要用map接收
    err = json.Unmarshal(hit.Source, &article)

    //获取每个id的对应点赞数
    digg := diggInfo[hit.Id]
    
    newDigg := article.DiggCount + digg
    if article.DiggCount == newDigg {
      logrus.Info(article.Title, "点赞数无变化")
      continue
    }
    _, err := global.ESClient.
      Update().
      Index(models.ArticleModel{}.Index()).
      Id(hit.Id).
      Doc(map[string]int{
        "digg_count": newDigg,
      }).
      Do(context.Background())
    if err != nil {
      logrus.Error(err.Error())
      continue
    }
    logrus.Info(article.Title, "点赞数据同步成功， 点赞数", newDigg)
  }
  redis_ser.DiggClear()
}
```

**缺陷**

```sh
1.当我们的文章数据量多时，这种遍历再更新的方式非常耗费性能，且容易出错。
--可以尝试遍历id，然后一条条去修改es的数据，但是那样当访问量大时，redis存储的数据也会很多。

2.应该有限制，只有登录才可以点赞。且只能点赞一次，点第二次就是取消。
```

### 文章点赞数据显示

在获取文章列表时可以同时获取点赞数



